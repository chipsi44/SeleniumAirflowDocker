{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Airflow and selenium !__\n",
    "\n",
    "__*Since you already made the scrapping part i'm going to re do it for you!*__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "def get_the_page_firefox(link) :\n",
    "        '''\n",
    "        Function that interact with selenium grid throught the port 4444 and Firefox.\n",
    "        Args : \n",
    "            link : str, link to the firefox webpage. In this project it's a YahooFinance page\n",
    "        Return : \n",
    "            driver : selenium object, connected to the firefox link\n",
    "        '''\n",
    "        #Connect to selenium grid\n",
    "        options = webdriver.FirefoxOptions()\n",
    "        options.accept_insecure_certs = True\n",
    "        driver = webdriver.Remote(\n",
    "        command_executor='http://selenium-container:4444/wd/hub',\n",
    "        options=options\n",
    "        )\n",
    "        #Help to get less crash to connection timeout\n",
    "        driver.set_page_load_timeout(60)\n",
    "        #Connect to the link\n",
    "        driver.get(link)\n",
    "        return driver\n",
    "\n",
    "def Accept_the_cookies_financeYahoo(driver) :\n",
    "    '''\n",
    "    This function is made to accept the cookies on the web page finance Yahoo\n",
    "    Args : \n",
    "         driver -> selenium object, already connected to the firefox YahooFinance page\n",
    "    '''\n",
    "    scroll_button = driver.find_element(By.ID, \"scroll-down-btn\")\n",
    "    scroll_button.click()\n",
    "\n",
    "    cookie_button = driver.find_element(By.XPATH, \"//button[@class='btn secondary accept-all ' and @name='agree']\")\n",
    "    cookie_button.click()\n",
    "\n",
    "#start scrapping\n",
    "def get_header_financeYahoo(driver) :\n",
    "    '''\n",
    "    Scrapes the header for a CSV file from Yahoo Finance and returns it as a list.\n",
    "    Args:\n",
    "        driver -> selenium object, already connected to the firefox YahooFinance page\n",
    "    return :     \n",
    "        my_header_list -> List of strings.\n",
    "    '''\n",
    "    thead_element = driver.find_element(By.TAG_NAME,\"thead\")\n",
    "    th_elem = thead_element.find_elements(By.TAG_NAME,\"th\")\n",
    "    my_header_list = []\n",
    "    for elem in th_elem[:-1] : \n",
    "        my_header_list.append(elem.text)\n",
    "    return my_header_list\n",
    "\n",
    "def get_entreprise(driver) :\n",
    "    '''\n",
    "    This function is used to get all the info about the differents entreprise stock availabe on the web page.\n",
    "    args : \n",
    "        driver -> selenium object, already connected to the firefox YahooFinance page\n",
    "    return : \n",
    "        entreprise_list -> list of str, contains info about the stock of differents entreprise.\n",
    "    '''\n",
    "    tbody_element = driver.find_element(By.TAG_NAME,\"tbody\")\n",
    "    tr_elem_from_tbody  = tbody_element.find_elements(By.TAG_NAME,\"tr\")\n",
    "    entreprise_list = []\n",
    "    for selenium_elem_tr in tr_elem_from_tbody :\n",
    "        td_elem_in_tr = selenium_elem_tr.find_elements(By.TAG_NAME,\"td\")\n",
    "        entreprise_list.append([])\n",
    "        for selenium_elem_td in td_elem_in_tr :\n",
    "            entreprise_list[-1].append(selenium_elem_td.text)\n",
    "    return entreprise_list\n",
    "\n",
    "\n",
    "def main_scrap_financeYahoo(link) :\n",
    "    '''\n",
    "    This function incorporates all of the above functions to navigate to a Firefox web page and scrape data.\n",
    "    Args : \n",
    "        link -> Str, link of the firefox webpage\n",
    "    return : \n",
    "        entreprise_list -> list of str, contains info about the stock of differents entreprise.\n",
    "        my_header_list -> List of str.\n",
    "    '''\n",
    "    driver = get_the_page_firefox(link)\n",
    "    Accept_the_cookies_financeYahoo(driver)\n",
    "    my_header_list = get_header_financeYahoo(driver)\n",
    "    entreprise_list = get_entreprise(driver)\n",
    "    try :\n",
    "        driver.close()\n",
    "        driver.quit()\n",
    "    except : \n",
    "        print(\"Driver not closed\")\n",
    "    return entreprise_list,my_header_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def to_pandas(entreprise_stock_info_list,my_header_list) :\n",
    "    for elem in entreprise_stock_info_list :\n",
    "            elem.pop()  # remove the last element of each inner list\n",
    "    df = pd.DataFrame(data=entreprise_stock_info_list, columns=my_header_list)\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can run the two code cells, and nothing should happen since they only create functions. However, you are highly encouraged to read the provided code!\n",
    "\n",
    "The main difference are the webdriver remote and the path to the CSV ! We'll see later why it's like this ! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
